import streamlit as st
import numpy as np
import os
import re
from langchain.callbacks import StreamlitCallbackHandler
from langchain_groq import ChatGroq

from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import Runnable
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
## Code #####
user_histories = {}
system_prompt = f"""You are CodeGenie, an expert software engineer and coding tutor.
Your job is to help users with code suggestions, debugging, and explanations across programming languages like Python, Java, C++, JavaScript, SQL, etc.

You always reply with:
- Clear, concise answers
- Relevant code blocks
- Helpful comments
- Language as asked by the user
- No extra text unless necessary"""

# Prompt template
prompt_template = ChatPromptTemplate.from_messages([
    ("system", system_prompt),
    MessagesPlaceholder(variable_name="chat_history"),
    ("human", "{input}")
])

# Streamlit UI
st.title("ðŸ¤– CodeGenie - Your Coding Assistant")

st.markdown("""
It's a code assistant that provides you with answers to your queries.  
It helps users with code suggestions, debugging, and explanations  
across languages like Python, Java, C++, JavaScript, SQL, etc.
""")

## Sidebar for settings
st.sidebar.title("Inputs")
user_name = st.sidebar.text_input("Enter your Name:")
groq_api_key = st.sidebar.text_input("Enter your Groq API Key:",type="password")
query = st.chat_input(placeholder="Write your query?")

if "messages" not in st.session_state:
    st.session_state["messages"]=[
        {"role": "assistant", "content": "Hi, I'm a code assistant. How can I help you?"}
    ]

for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg['content'])

if user_name and groq_api_key and query:
    st.session_state.messages.append({"role": "user", "content": query})
    st.chat_message("user").write(query)
    
    llm3 = ChatGroq(model="llama-3.3-70b-versatile",
                   groq_api_key=groq_api_key,
                    temperature = 0.2,  # for randomness, low- concise & accurate output, high - diverse and creative output
                  max_tokens = 300,   # Short/long output responses (control length)
                    model_kwargs={
                               "top_p" : 0.5,        # high - diverse and creative output
                                })
    
    chain: Runnable = prompt_template | llm3
    
    if user_name not in user_histories:
        user_histories[user_name] = []
    history = user_histories[user_name]

    with st.chat_message("assistant"):
        st_cb=StreamlitCallbackHandler(st.container(),expand_new_thoughts=False)
        response=chain.invoke({"input": query,"chat_history": history}, callbacks=[st_cb])
        final_answer = response.content if hasattr(response, "content") else str(response)
        st.write(final_answer)
        st.session_state.messages.append({'role': 'assistant', "content": final_answer})
        
        # Store conversation
        history.append(HumanMessage(content = query))
        history.append(AIMessage(content = final_answer))
elif user_name and groq_api_key and not query:
    st.warning("Please type a coding question to get started.")
elif not user_name or not groq_api_key:
    st.info("ðŸ‘ˆ Please enter your name and Groq API key in the sidebar to continue.")

